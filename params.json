{
  "name": "Mlnd",
  "tagline": "A Wiki containing helpful information for new and existing students of the Machine Learning Nanodegree at Udacity. Written by students of the Nanodegree.",
  "body": "# Welcome!\r\n\r\nHi there! It looks like you're new here. This document is meant to act as a comprehensive tour of our team, so you can jump right in with everyone right away.\r\n\r\nPlease have a look at our [community guidelines](https://github.com/machinelearningnanodegree/MLND/wiki/Community-Guidelines) when you have a chance.\r\nAlso have a look at the [tips and tricks](https://github.com/machinelearningnanodegree/MLND/wiki/Tips-and-Tricks) compiled by previous students.\r\n\r\nThe Team Admins are:\r\n- Devon (@geekman2)\r\n- Nash (@nash)\r\n- Bharat (@param.bharat)\r\n- Gilad (@giladgressel)\r\n- Joshua (@joshuacook)\r\n- David (@dtimm)\r\n\r\nPlease understand we are students just like you! \r\n\r\nIf you have any questions, comments or concerns about Slack team, or just about how something works feel free to ping us either individually or in `#to_admin`, one of us is active almost 24/7\r\n\r\nSome Slack tips:\r\n- You can write single-line code in a message by wrapping it in backticks \\` , and multi-line code with three, like this \\```\r\n- Snippets, which can be created by hitting the plus sign on the left, are for large code blocks\r\n- Make sure to set your notifications, slack allows great customization, you can set notifications by specific words, and by specific channels.\r\n- You can `@mention` someone and it will notify them.  Please do not use the `@channel` notification.\r\n\r\n[Here](https://docs.google.com/document/d/1leih0E5mq0tpgKHClgChv-Hr0Xm0sitW25gzuc1VCdY/edit?usp=drivesdk) are some cool machine learning ideas that anyone can pick up. And once you've decided, add it to [our list](https://docs.google.com/spreadsheets/d/1KI8Wf0eaoNCzVd7r1MkQb5hg5rbMTXm5kNdwCh1l7Yc/edit#gid=0).\r\n\r\n# Community Guidelines\r\n\r\nHey folks, thanks for stopping by to read these guidelines.  We wrote these in order to come together and agree upon a set of community values so that we can grow together as a team and have loads of fun.\r\n\r\nThese are all things we strongly believe in and hope you do too.\r\n\r\n## We are a community of learners\r\n- If someone asks for help, _teach them to fish_.   The person should have already watched the video, and Googled a bit, so assume they’ve tried and are stuck.  You can start by saying, “tell me what you do understand, and at what part you’re getting stuck.”  Then work from there\r\n- Please do not give out code related to projects as this violates Udacity's honor code.\r\n\r\n## Slack Etiquette\r\n- Direct Messaging is available, but we really like the community space, so please consider if your conversation could be public in #general, we’d love to join in and discuss! Community takes public participation, so please consider braving the waters, we won’t bite!\r\n- Do not use the @channel tag.  It notifies everyone, and it’s never appropriate.  Unfortunately we cannot disable this\r\n- Using @here is totally ok\r\n- Please keep discussions in the correct channels.  This may seem a little strange at first, having two simultaneous conversations with the same people in two separate channels, but the reality is that it helps people’s ideas be heard.  The chat moves quickly, if we have multiple topics in one channel, it’s very difficult to discuss anything\r\n- If you are discussing something, and someone suggests you move to one of the other channels, it’s probably a good idea, don't worry most of the time we all follow each other into other channels.\r\n- Please refrain from using any swear or cuss words.\r\n\r\n### A few things to consider\r\n- Everyone in the MLND comes from different backgrounds, education, family (married, kids, single, student, retired), so please don’t make assumptions about others and be kind and respectful to everyone\r\n- Disagreeing is OK! And in fact it’s encouraged. We want productive discussions so we can all learn and get different perspectives. Just be polite and respectful\r\n- Should you at any time use the term **optimize** or any of it's variants, be sure to enclose it in asterisks\\*, so it is bolded. You'll feel like part of the gang in no time!\r\n- Should the need arise (as it so often does) to say something sarcastic, use official sarcasm punctuation `~.` for dry sarcasm. `~!` for enthusiastic sarcasm. And `~?` for sarcastic/rhetorical questions\r\n\r\n\r\n## Channels\r\n- We have a fair amount of channels.  Join the ones you are interested in. Every channel has a purpose and description. If you think we need a new channel, suggest it in #general; if there is a good response, you should request it in \\#to_admin\r\n- \\#ask_udacity is for any curious questions you have for Udacity staff, but please keep in mind that they are here almost purely as observers, questions requiring official response should be directed to either the forums or machine-support@udacity.com\r\n- We do not have channels specific to the projects!  This is on purpose. The idea is that we don’t want to encourage “how do I do x, y or z”, we prefer to talk about theory, ideas and techniques.  It is totally OK to ask project specific questions in appropriate theory channels (supervised, unsupervised, reinforcement learning), we just don’t want to focus solely on the projects in our conversations\r\n- There is a \\#beginners channel, we encourage everyone to participate there, but the conversation should be initiated by those with questions\r\n- If you ask a question in a channel but aren’t getting a response, make sure that there are people in the channel.  It’s ok to `@mention` someone if you’d like to ask them to the join the channel to help with the discussion (@mention will automatically invite them into the channel).  If you are still stuck and not getting help, try #general, but be prepared for others to tell you “sorry, I don’t have time”, or “I don’t know”\r\n\r\n### Channel List\r\n- `#Algorithms`\r\n    - This channel is for discussion of algorithms, how they work, what they do, and when to use them\r\n- `#CodeBugs`\r\n    - When your code doesn't work and you can't figure out why, ask it here\r\n- `#DataWrangling`\r\n    - Once you get to your capstone you'll have to clean and arrange your data, this channel is for all such questions and information\r\n- `#MLReads`\r\n    - This channel is full of little readable goodies about Machine Learning, consisting of articles, books, and some courses\r\n- `#Careers`\r\n    - Interviews, resumes, and job oppurtunities, post about it here\r\n- `#Improve_MLND`\r\n    - This channel is monitored by the course managers, if there's something that needs improvement in the MLND, discuss it here, we're good listeners\r\n- `#Ideas`\r\n    - Just had that idea that will change the world? Shoot a message into this channel and discuss away\r\n- `#Reinforcement-Learning`\r\n    - Discussion about reinforcement learning, including, but not limited to, Project 4\r\n- `#To_Admins`\r\n    - Questions comments and concerns, addressed to the student run team slack\r\n- `#To_Udacity`\r\n    - To ask specific questions about the MLND  program or questions about Udacity. This channel should not be used for content or project-related discussion.\r\n\r\n**BE NICE!**\r\nReally.\r\n\r\n# Integrations\r\nInvitations to our community are sent out automatically by an app running on a remote server. The app was built using this github [repo](https://github.com/outsideris/slack-invite-automation). \r\n\r\nQuestions should be directed to @joshuacook.\r\n\r\n#Regular Events\r\nThis page maintains a list of regular events initiated by the students in the MLND slack team. If you'd like your event listed here, please request it in **#to_admin**\r\n\r\n\r\n## Bi-Weekly ML Paper Readings:\r\nEvery week or two, we organize a reading of a ML article.  The article is suggested by a member who would like to present it, and everyone reads it ahead of time.  Then a discussion takes place during a set time using a live video chat program.  \r\nPlease stop by **#mlreads** to learn about the latest paper.  \r\n**We just finished reading : http://karpathy.github.io/2016/05/31/rl/**  \r\n**We are now going to be reading : https://medium.com/@aliciatweet/overcoming-impostor-syndrome-bdae04e46ec5#.w1n428gyd**\r\nand **http://www.paulineroseclance.com/pdf/ip_high_achieving_women.pdf**\r\n\r\n\r\nWe have an open Doodle poll for the best time to have our meetup: doodle closed, result below\r\n\r\n**http://www.timeanddate.com/worldclock/fixedtime.html?iso=20160903T0700&p1=202&msg=Imposter%20Syndrome%20Discussion&fromtheme=generic**\r\n\r\n\r\n## Linear Algebra Math Class\r\nFeel like you really wish you knew more linear algebra?  You are in luck!  \r\nHead over to **#mit_1806** and join us for a weekly math session.  We will be following MIT 18.06 Linear Algebra, Spring 2005.   \r\n@joshuacook is leading this adventure, he has taken many linear algebra courses, and is a numpy expert, so we are lucky to have him!\r\n\r\n**check out our github for the course: https://github.com/machinelearningnanodegree/mit_1806**\r\n\r\n#Supplementary Materials\r\n\r\nExcellent Material on how to [organize your data-science project](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000424)\r\n\r\n## To Contribute Resources\r\nIf you have a resource you would like to share with the group, bring it to the attention of the Slack admins in `#to_admin`, and we'll add it to our list for everyone to see.\r\n\r\n## Sites\r\n- [Chris Olah](http://colah.github.io/)\r\n- [Google Unofficial DataScience Blog](http://www.unofficialgoogledatascience.com/)\r\n- [Jake Vanderplas](https://jakevdp.github.io/)\r\n- [RedBlobGames](http://www.redblobgames.com/)\r\n\r\n## Textbooks and Links\r\n### Machine Learning\r\n- [*Deep Learning*](http://www.deeplearningbook.org/), Ian Goodfellow and Yoshua Bengio and Aaron Courville\r\n- *Introduction to Statistical Learning*, Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani, available for free [here](http://www-bcf.usc.edu/~gareth/ISL/)\r\n    - Intended as companion piece to *Elements of Statistical Learning*, Hastie, Tibshirani, Friedman\r\n    - Read Intro first. Even if you have a PhD in statistics.\r\n- *Machine Learning*, Tom Mitchell website [here](http://www.cs.cmu.edu/~tom/mlbook.html)\r\n- *Artificial Intelligence*, Stuart Russell and Peter Norvig, website [here](http://aima.cs.berkeley.edu/)\r\n- *Linear Algebra Review and Reference*, Zico Kolter [here](http://cs229.stanford.edu/section/cs229-linalg.pdf)\r\n- *Stanford CS 229 course*, Machine Learning, [here](http://cs229.stanford.edu/materials.html)\r\n- *Python Implementation of CS 229* [here](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/)\r\n- *Machine Learning for Audio, Image, and Video Analysis*, Camastra, Vinciarelli \r\n- *Pattern Recognition and Machine Learning*, Bishop \r\n- *Python 3 Text Processing with NLTK 3 Cookbook*, Perkins \r\n- *Thoughtful Machine Learning*, Kirk\r\n- http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\r\n- http://machinelearningmastery.com/rescaling-data-for-machine-learning-in-python-with-scikit-learn/\r\n- http://sebastianraschka.com/faq/docs/when-to-standardize.html\r\n- http://www.statsoft.com/textbook/k-nearest-neighbors\r\n- https://www.analyticsvidhya.com/blog/2014/10/introduction-k-neighbours-algorithm-clustering/\r\n- https://www.analyticsvidhya.com/blog/2015/09/naive-bayes-explained/\r\n- http://stackoverflow.com/questions/29438265/stratified-train-test-split-in-scikit-learn\r\n- https://medium.com/@ageitgey\r\n\r\n### Mathematics\r\n- [A free source for math textbooks](http://aimath.org/textbooks/)\r\n- *An Introduction to the Conjugate Gradient Method Without the Agonizing Pain*, Shewchuck \r\n- *Computational science and engineering*, Gilbert Strang \r\n- *Concrete Mathematics*, Graham, Knuth, Patashnik\r\n- *Introduction to Linear Algebra*, Gilbert Strang\r\n    - My favorite book of all time, @joshuacook (seconded, @nash)\r\n    - Ask @joshuacook about why linear algebra is the bee’s knees and how to study it\r\n- *Introduction to Mathematical Statistics*, Hogg \r\n- *Linear Algebra Done Right*, Axler \r\n- *Linear Algebra Done Wrong*, Treil \r\n- *Linearity, Symmetry, and Prediction in the Hydrogen Atom*, Singer \r\n- *Pearls in Graph Theory*, Hartsfield, Ringel\r\n- [*Convex Optimization*](https://web.stanford.edu/~boyd/cvxbook/), Stephen Boyd and Lieven Vandenberghe\r\n\r\n### Python and Programming\r\n- *A Guide to Numpy*, Travis Oliphant free [here](http://web.mit.edu/dvp/Public/numpybook.pdf)\r\n    - Timothy Oliphant wrote numpy and now runs Continuum Analytics\r\n- *All the Mathematics You Missed But Need to Know for Graduate School*, Garrity \r\n- *Becoming a Better Programmer*, Pete Goodliffe\r\n- *Data Structures and Algorithms in Python*,  Goodrich, Tamassia, Goldwasser \r\n- *Effective Computation in Physics*, Scopatz, Huff\r\n- *Expert Python Programming*, Ziade \r\n- *Flask Web Development*, Grinberg\r\n- *Fluent Python*, Ramalho\r\n- *Functional Python Programming*, Lott \r\n- *Introduction to Computing Using Python*, Perkovic \r\n- *IPython Interactive Computing and Visualization Cookbook*, Rossant \r\n    - IPython Notebook is now called Jupyter. Still a great reference.\r\n- *Learn Python the Hard Way*, Zed Shaw\r\n- *Numerical Python*, Johansson\r\n- *NumPy Cookbook*, Idris \r\n- *Python Scripting for Computational Science*, Langtangen \r\n- *Python 3 Object Oriented Programming*, Phillips \r\n- *SciPy and NumPy*, Bressert \r\n- *scikit-learn Cookbook*, Hauck\r\n- *Structure and Interpretation of Computer Programs*, Abelson, Sussman \r\n- *The Pragmatic Programmer*, Hunt, Thomas \r\n- *The TexBook*, Knuth\r\n\r\n#### The Think Series\r\n[A series of books by Allen Downey](http://greenteapress.com/wp/think-python/). Excellent introduction and exploration of Python topics both related to the Python Data Model and Mathematical Python.\r\n\r\n- *Think Python* (free)\r\n- *Think Bayes*\r\n- *Think Stats*\r\n- *Think Complexity*\r\n- *Think DSP*\r\n\r\n### Installing Jupyter\r\nJupyter is extremely well documented. Their installation instructions are [here](http://jupyter.readthedocs.io/en/latest/install.html).\r\n\r\nIf you are feeling adventurous, running Jupyter via Docker is not only very well supported, it might even in the long run be easier. Here is how to run Jupyter in Docker:\r\n\r\n1. Install Docker - instructions for [Mac](https://www.docker.com/products/docker#/mac), [Windows](https://www.docker.com/products/docker#/windows), and [Linux](https://www.docker.com/products/docker#/linux).\r\n2. From the command line type:\r\n    - $ `docker run jupyter/scipy-notebook`\r\n3. When the above process completes (downloading the jupyter/scipy-notebook image from Docker Hub), it should start and now be running (usually at localhost:8888). Enter that URL in your browser.\r\n\r\n# Tips and Tricks for the Machine Learning Nanodegree (MLND)\r\n*Based on previous students experiences - please add yours!*\r\n\r\nHow to get help from Udacity Staff regarding technical matters (tuition, grading, submissions):\r\nmachine-support@udacity.com\r\n\r\n## Data Analysis\r\nIf you feel like you are being thrown in the deep end with data wrangling and exploratory analysis, we recommend you seriously consider taking a step back and pursuing the Data Analyst Nanodegree (DAND). If you aren’t drowning, but struggling, then consider the following individual courses:\r\n\r\n1. [Intro to Data Analysis](https://www.udacity.com/course/intro-to-data-analysis--ud170)\r\n    - Rated beginner level, this course gives intuition about how to ask questions of your data and explore it, as well as Numpy and Pandas experience\r\n2. [Intro to Data Science](https://www.udacity.com/course/intro-to-data-science--ud359)\r\n    - Rated Intermediate level, this course takes you through the entire data science process: statistical analysis, data wrangling, exploratory and explanatory visualization, machine learning (basic), and even some MapReduce\r\n    - A note on these two courses: Intro to Data Analysis was created to replace Intro to Data Science in the DAND, and was intended to be easier material and a more open ended project in terms of the dataset. One suggestion is to select one of these courses, based on your comfortability with data science (Intro to Data Analysis being the easier of the two). Of course, you can always take both if you have the time\r\n3. [Data Wrangling with MongoDB](https://www.udacity.com/course/data-wrangling-with-mongodb--ud032)\r\n    - This incredibly practical course will get you comfortable writing data parsing scripts to handle data in CSV, JSON, XML, and HTML formats, as well as give you experience with MongoDB syntax for storing and querying data. Highly recommended as this is one of the most practical skills you can have -- as they say, 80% of data science is cleaning the data. For reference, it took Nash(@nash) 4 months to clean his capstone dataset, he isn't even finished yet! (seriously, we will update this if he ever finishes)\r\n\r\nWe believe these courses will get you relatively up-to-speed on the data science process.\r\n\r\n## Videos\r\nBecause the video material for this Nanodegree (ND) is taken from multiple existing Udacity courses, it can seem jarring at times, or missing material. One great option is to just simply watch the entire video series, in their original format, as Udacity Classes.\r\n\r\n1. Intro to Machine Learning - Katie and Sebastian give practical advice in sklearn, this is very useful for Projects 1-3.\r\n2. GA Tech Machine Learning - Charles and Michael talk theory theory and more theory, **it’s OK if you don’t understand everything they say (really!)**, useful for Projects 2-4.\r\n3. GA Tech Reinforcement Learning - deeper theoretical material, e.g. convergence, multi-agent game theory, useful for Project 4.\r\n\r\n## Projects\r\n### P0 Titanic\r\nRemember in math class when you would be first introduced to something like finding a derivative and you would need to do every single derivative by hand? Then you would be introduced to the general faster method that everyone uses. Having done it by hand helped you to understand the faster method. This project is essentially implementing a decision tree by hand. Not in a machine learning sense - you are not coding the CART algorithm by hand - but rather in the sense that you create a binary decision tree by programming a series of rules on a data set. If you’ve never seen Jupyter before it’s a great introduction. \r\n### P1 Boston Housing \r\nThis project is meant as a sort of warm-up.  It’s meant to teach you best practices for model evaluation.  Instead of first teaching you about algorithms, the course instructors decided to first teach the correct workflow for a machine learning problem.  So if you don’t understand how the algorithm works, don’t worry you aren’t supposed to yet.  You are supposed to learn about correct model validation and setup.  That means splitting your data into training and testing, looking at learning graphs (to check for overfitting / underfitting) and at the end doing cross-validation.  The project may be easier than you think it should be. So if you are finding it too plain and simple and think you are missing some thing -- you aren’t.\r\n### P2 Student Intervention\r\nIn this project you need to implement different algorithms and test them against each other.  In its current form (8/16/2016) the dataset is quite small, and this makes any meaningful comparison a bit trivial.  Still, you can get value out of the process and learn to compare and contrast algorithms.\r\n#### General stumbling points\r\n- People struggle to get an “intuition” as to what algorithms to choose and why\r\n    - This is totally normal and expected.  Don’t sweat it, just pick something. \r\n    - The dataset is so small that re-running randomized train-test-splits will cause big variations in your results.  It’s highly recommended to set “random-seed = 0” (or any integer - just keep it the same) so you can test with the same data split for comparisons.\r\n    - Alternately, make multiple runs (>5) with each classifier and average the results\r\n- People struggle to answer this question: What makes this model a good candidate for the problem, given what you know about the data?\r\n    - Most people find it very difficult to know anything about the data.  This question makes it sounds like there is an easy way to know something.  It’s really not that simple, but do your best.\r\n    - Udacity forum thread: [selecting models based on data](https://discussions.udacity.com/t/selecting-models-based-on-data/39559)\r\n\r\n\r\n#### Accelerated Timeline for Video Lessons (Supervised Learning)\r\nIf you are looking to extract the core information from the lessons, without getting bogged down in high level mathematical theory, we recommend the following:\r\n\r\nWatch the supervised learning section of “Intro to Machine Learning” (units 1-4) first, to get an overview, then the supervised learning section of “GA Tech Machine Learning” for in-depth theory of what you’re actually doing. You’ll have an added advantage if you watch the videos from week 1,2,3 and 7 of [Coursera’s Machine Learning course taught by Andrew Ng](https://www.coursera.org/learn/machine-learning).\r\n\r\n*Finally, the PDFs found under the resources section, are all really good!*\r\n\r\n### P3 Customer Segments\r\nUnsupervised learning, including clustering, PCA, and ICA. The material in the unsupervised learning section of “GA Tech Machine Learning” should be sufficient. The randomized optimization material won’t come up, so it’s not necessary for the project. Neither is information theory. Week 8 in Andrew Ng’s course will help you understand the math better.\r\n\r\n#### Common Struggles:\r\n- The renders.py library is a custom file, you can read the code if you like, it’s in the zip.  However there is no documentation\r\n\r\n### P4 Training a Smartcab\r\nThis project is quite different from the others in that it’s not in an IPython Notebook and it’s got a lot of code, which is quite confusing at first.  It’s a challenge for a lot of students to figure out “what to do”, so we highly suggest reading up in the forums.  A lot of questions have been asked and answered there.\r\n\r\nHere is a basic overview:\r\n\r\nYou are going to implement a basic Q learning algorithm using tables. The goal of the Q-learning implementation is basically to create an agent that follows the rules of the road.   The project should be called “Training a smart cab to drive safely”, because you don’t need to give the cab instructions on where to go!  That’s handled by the project’s “planner”.\r\n\r\nThe most important unit in “GA Tech Machine Learning” for this section by far is “Reinforcement Learning, Lesson 2: Reinforcement Learning”. Game theory is not involved (but it’s still excellent material). Use the papers in the reading material section to get an idea on how you could implement Q-Learning. \r\n\r\n\r\n## Different Tips from Different People!\r\n*See if anything seems like you’d want to try it out, not everyone learns the same way.*\r\n\r\n- If you are having trouble following along, watch all the videos twice, the first time watch at 1.5-2x speed, and just watch to get key points and highlights, then watch all the way through again at normal speed, and take thorough notes\r\n- If a question seems easy, it is! Don’t stress about it.\r\n- You might have some trouble with getting pygame working, if that’s the case search the forums and ping the slack group if you are stuck.\r\n- Get Anaconda, it’s just way easier, (pygame might be an issue)\r\n- You have unlimited resubmissions, so don’t sweat some feedback,\r\n- The forums are a great resource, use them! \r\n- If you can't find an answer on the forums or you want to talk to someone in real-time,  don’t be shy to ask on Slack. We’ll have a real-time conversation, and chances are you’ll get a bunch of people involved (which is good, cause it’s fun).\r\n\r\nPlease add your name below if you added material to this document.\r\n\r\n### Contributions by:\r\n- Nash Taylor\r\n- Devon Muraoka\r\n- Bharat Ramanathan\r\n- Joshua Cook\r\n- Gilad Gressel\r\n- David Timm",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}